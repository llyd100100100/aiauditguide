(1) Data Integrity(데이터 무결성) 준수 요건(예: FDA 21 CFR Part 11, ALCOA+ 원칙)을 기반으로 Audit Trail에서 필수적으로 검토해야 할 이상 징후 패턴(비정상적 로그인, 메타데이터 조작 의심, 권한 없는 변경 등)을 구체화 및 정의.
(2) 민감한 Audit 데이터를 외부 API(GPT, Claude 등)로 전송할 때 발생할 수 있는 데이터 유출 위험을 분석하고, 이를 방지하기 위한 기술적 조치(PII 마스킹, 토큰화, Enterprise API의 Data Privacy 정책 활용 등) 조사.
(3) 다양한 시스템의 Audit 파일 형식(CSV, XML, JSON, 비정형 Log 등)을 AI가 처리 가능한 형태로 표준화하고 파싱(Parsing)하기 위한 전처리 모듈 아키텍처 탐색.
(4) 사용자의 요구사항(초기 API -> 추후 로컬 LLM 전환)을 충족하는 아키텍처 옵션들을 비교 분석:
(a) Option 1: 빠른 검증을 위한 경량화 아키텍처 (Streamlit/Gradio + Python Backend + Public API)
(b) Option 2: 보안과 확장을 고려한 중급 아키텍처 (React/Vue + FastAPI + Vector DB + Azure/AWS Private AI)
(c) Option 3: 향후 로컬 전환이 용이한 모듈형 아키텍처 (LLM 추상화 레이어 도입)
(5) 프로토타입 단계에서 API 비용 효율성을 높이고, 추후 로컬 하드웨어(On-premise GPU 서버) 도입 시 필요한 하드웨어 사양 및 오픈소스 LLM(Llama, Mistral 등)의 성능 벤치마킹 데이터 조사.
(6) AI가 단순 탐지를 넘어 '설명 가능한 AI(XAI)'로서 감사 결과에 대한 근거를 제시하고, 사용자가 피드백을 주어 모델을 개선할 수 있는 Human-in-the-loop 프로세스 가능성 탐색.
(7) 위 분석 내용을 종합하여 시스템의 목적, 범위, 사용자 인터페이스, 데이터 처리, 보안 요구사항, 하드웨어 및 소프트웨어 제약 사항을 포함한 체계적인 URS(User Requirement Specification) 문서 초안 작성.