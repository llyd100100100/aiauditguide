Phase 1 프로토타입 구축: Google Antigravity와 Gemini 3.0 기반의 보안 중심 AI 데이터 분석 시스템1. 서론: 바이브 코딩(Vibe Coding) 시대의 프로토타이핑 전략1.1 프로젝트 개요 및 전략적 목표본 보고서는 Phase 1 프로토타입 구축을 위한 기술적 청사진과 실행 전략을 포괄적으로 다룬다. 사용자의 핵심 요구사항은 기존의 안정적인 기술 스택인 Python, Streamlit, Pandas, Presidio를 유지하면서, AI 추론 엔진을 구글의 최신 'Gemini 3.0 API'로 업그레이드하는 것이다. 이는 단순한 모델 교체가 아니라, 기존의 생성형 AI가 가진 단순 텍스트 완성 기능을 넘어선 '에이전트적 추론(Agentic Reasoning)'과 '초거대 컨텍스트 처리' 능력을 시스템의 핵심 두뇌로 이식하는 과정을 의미한다.특히 이번 개발 프로세스는 구글의 차세대 AI 기반 IDE인 'Google Antigravity'를 활용한 '바이브 코딩(Vibe Coding)' 방법론을 채택한다. 바이브 코딩은 개발자가 코드의 구문(Syntax)을 직접 작성하는 것이 아니라, 시스템의 '의도(Intent)'와 '상태(State)'를 자연어로 정의하고, 고지능 에이전트가 이를 구현하게 하는 새로운 개발 패러다임이다. 따라서 본 보고서의 핵심 산출물인 '마스터 프롬프트(Master Prompt)'는 단순한 지시문이 아니라, 에이전트가 따라야 할 엄격한 기술 사양서이자 헌법과 같은 역할을 수행하게 된다.1.2 기술적 배경과 Gemini 3.0의 도래2025년 12월과 2026년 1월에 걸쳐 공개된 정보들에 따르면, Gemini 3.0은 전작인 1.5 Pro나 2.5 Flash와는 질적으로 다른 아키텍처를 보여준다. Gemini 3.0은 'Deep Think'라 불리는 심층 추론 기능을 내재화하여, 복잡한 데이터 분석 작업에서 발생할 수 있는 환각(Hallucination) 현상을 억제하고 논리적 정합성을 획기적으로 높였다. 또한, 100만 토큰 이상의 컨텍스트 윈도우를 기본적으로 지원하여 대용량 Pandas DataFrame의 구조를 파악하는 데 있어 탁월한 성능을 발휘한다.그러나 이러한 고지능 모델의 도입은 역설적으로 보안의 중요성을 더욱 부각시킨다. 모델이 데이터를 더 깊이 '이해'할수록, 민감 정보(PII)가 유출될 경우 발생할 수 있는 리스크 또한 커지기 때문이다. 따라서 본 프로젝트는 Microsoft Presidio를 활용한 로컬 기반의 PII 익명화(Anonymization) 계층을 AI 추론 이전에 강제함으로써, 'Zero Trust' 보안 모델을 구현하는 것을 절대적인 전제 조건으로 한다.2. 아키텍처 패러다임: 에이전트 기반 개발과 보안의 융합2.1 Google Antigravity와 바이브 코딩의 본질Google Antigravity는 기존의 IDE(통합 개발 환경)가 제공하던 코드 자동 완성을 넘어, 개발 프로세스 전반을 관리하는 '에이전트 매니저(Agent Manager)' 역할을 수행한다. 이는 개발자가 "디렉터(Director)"가 되고 AI가 "스크립트 작가(Scriptwriter)"가 되는 역할의 전환을 의미한다. Antigravity 환경에서의 개발은 '슬롯머신'처럼 운에 맡기는 코드 생성이 아니라, 명확한 계획(Plan)과 아티팩트(Artifact) 검증을 통해 이루어진다.특징전통적 코딩 (Traditional Coding)바이브 코딩 (Vibe Coding with Antigravity)개발자의 역할구문 작성 및 로직 구현 (Implementation)의도 정의 및 아키텍처 감독 (Orchestration)입력 방식코드 에디터 타이핑자연어 프롬프트 및 컨텍스트 제공AI의 역할코드 조각 추천 (Copilot)전체 모듈 구현, 디버깅, 테스트 수행 (Agent)검증 방식단위 테스트 작성아티팩트(Artifact) 실행 및 시각적 검증주요 리스크구문 오류, 로직 버그요구사항 오해, 환각(Hallucination), 보안 누락Phase 1 프로토타입에서 Antigravity 에이전트는 'Planning Mode'를 통해 먼저 구현 계획을 수립하고, 사용자의 승인을 얻은 후 코드를 작성하는 절차를 밟아야 한다. 이는 AI가 무작위로 코드를 뱉어내는 것을 방지하고, 우리가 정의한 보안 스택(Presidio)을 정확히 임포트하도록 강제하는 핵심 절차이다.2.2 보안 아키텍처: Gemini 3.0과 Presidio의 역할 분담시스템은 명확히 구분된 두 가지 영역, 즉 '신뢰 영역(Local Trust Zone)'과 '비신뢰 영역(Cloud Inference Zone)'으로 나뉜다.신뢰 영역 (Local Trust Zone): Streamlit 애플리케이션이 실행되는 로컬 환경(또는 보안 서버)이다. 여기서 사용자가 업로드한 CSV 데이터가 메모리에 로드된다. 이 단계에서 Microsoft Presidio가 작동하여 모든 텍스트 데이터에 대한 개체명 인식(NER)을 수행하고, 식별된 PII를 비식별화 토큰(예: <PERSON_1>, <PHONE_MASKED>)으로 치환한다.비신뢰 영역 (Cloud Inference Zone): Google Gemini 3.0 API가 위치한 영역이다. 이곳으로는 오직 Presidio를 통과하여 소독(Sanitized)된 데이터만이 전송된다. Gemini 3.0은 원본 데이터를 결코 볼 수 없으며, 오직 익명화된 데이터 패턴만을 분석하여 통찰을 제공한다.이러한 단방향 데이터 흐름(Unidirectional Data Flow)은 GDPR 및 개인정보보호법 준수를 위한 기술적 보호 조치의 일환이며, 프로토타입 단계에서부터 확고히 정립되어야 할 아키텍처 원칙이다.3. 핵심 기술 스택 심층 분석 및 마이그레이션 전략3.1 AI 엔진: Gemini 3.0 API (google-genai)기존의 Gemini 1.5 Pro나 Flash 모델을 사용하던 프로젝트들이 3.0으로 넘어오면서 가장 크게 변경되는 점은 SDK의 구조와 파라미터 튜닝 방식이다.3.1.1 SDK 변경: google.generativeai에서 google-genai로Gemini 3.0은 새로운 통합 SDK인 google-genai를 통해 접근하는 것이 권장된다. 기존의 google.generativeai 패키지는 레거시 모델 호환성을 위해 유지되지만, 3.0의 고급 기능인 'Thinking Mode'나 'Search Grounding'을 온전히 제어하기 위해서는 새로운 클라이언트 객체(genai.Client)를 사용해야 한다.특히 Gemini 3.0은 추론 능력(Reasoning Effort)이 강화되면서, API 호출 시 temperature 설정에 매우 민감하게 반응한다. 연구 자료에 따르면, Gemini 3.0 모델에서 온도를 명시적으로 설정하지 않을 경우 기본값이 1.0으로 설정되어, 데이터 분석과 같은 정밀한 작업에서 논리적 비약을 일으키거나 무한 루프에 빠질 위험이 있다. 따라서 마스터 프롬프트에는 반드시 temperature를 0.0 또는 0.1과 같은 낮은 값으로 강제하는 설정 코드가 포함되어야 한다.3.1.2 추론 토큰(Reasoning Tokens)과 지연 시간 관리Gemini 3.0은 복잡한 질문에 답하기 위해 내부적으로 '생각하는 시간'을 갖는다. 이는 사용자가 느끼기에 응답 지연(Latency)으로 나타날 수 있다. 따라서 Streamlit 프론트엔드에서는 이러한 비동기적 지연 시간을 사용자 경험(UX) 적으로 풀어내기 위해 st.spinner나 진행률 표시줄을 적극적으로 활용해야 하며, 백엔드 로직은 타임아웃이 발생하지 않도록 비동기 처리(Async/Await) 패턴을 고려해야 한다.3.2 보안 엔진: Microsoft Presidio의 정밀 구성Presidio는 크게 두 가지 엔진으로 구성된다: Presidio Analyzer와 Presidio Anonymizer.Analyzer (분석기): 텍스트에서 PII를 찾아내는 역할을 한다. 기본적으로 spaCy의 NLP 모델을 사용하는데, 영어권 데이터의 경우 en_core_web_lg (Large 모델)를 사용하는 것이 sm (Small 모델) 대비 인식률이 월등히 높다. 따라서 프로토타입 환경 설정 시 대용량 언어 모델의 다운로드가 선행되어야 함을 마스터 프롬프트에 명시해야 한다.Anonymizer (익명화기): 찾아낸 PII를 처리한다. 단순 마스킹(***)보다는 '치환(Replace)' 연산자를 사용하여 <PERSON>, <EMAIL>과 같은 태그로 변경하는 것이 Gemini 3.0이 문맥을 이해하고 분석하는 데 유리하다. 예를 들어 "홍길동이 이메일을 보냈다"를 "***이 ***을 보냈다"로 바꾸면 문맥이 파괴되지만, "이 을 보냈다"로 바꾸면 AI가 "사람이 이메일을 발송한 행위"를 인지할 수 있다.3.2.3 Pandas DataFrame과의 통합 이슈Presidio는 기본적으로 텍스트 문자열 입력을 가정한다. 수만 행의 데이터가 담긴 Pandas DataFrame의 각 셀(Cell)마다 Presidio를 호출하면 오버헤드로 인해 시스템이 마비될 수 있다. 따라서 'Batch Processing' 전략이 필요하다. 텍스트 컬럼 전체를 하나의 문자열로 결합하여 처리하거나, Presidio의 배치 처리 API를 활용하는 효율적인 래퍼(Wrapper) 함수 구현이 필수적이다.4. 상세 구현 가이드: 마스터 프롬프트 설계이 섹션은 사용자가 Google Antigravity의 에이전트 매니저에게 입력해야 할 실제 '마스터 프롬프트'의 내용을 담고 있다. 이 프롬프트는 위에서 분석한 모든 기술적 제약 사항과 아키텍처 요구사항을 에이전트가 이해할 수 있는 지시문 형태로 변환한 것이다.4.1 마스터 프롬프트 (Master Prompt)[Antigravity Agent Input]프로젝트 명세서: Gemini 3.0 기반 보안 데이터 분석 대시보드 (Phase 1)1. 프로젝트 개요 및 목표당신은 현재 Google Antigravity IDE 내에서 수석 소프트웨어 아키텍트(Principal Software Architect)이자 파이썬 엔지니어의 역할을 맡고 있습니다.우리의 목표는 **"민감 정보(PII)가 완벽하게 보호되는 상태에서 Gemini 3.0의 추론 능력을 활용하는 데이터 분석 프로토타입"**을 구축하는 것입니다.이 프로젝트는 '바이브 코딩(Vibe Coding)' 방법론을 따르므로, 당신은 코드를 작성하기 전에 반드시 **구현 계획(Implementation Plan)**을 먼저 수립하고, 나의 승인을 받아야 합니다.2. 기술 스택 (엄격 준수)Language: Python 3.10 이상Frontend: Streamlit (streamlit)Data Processing: Pandas (pandas)Security & Anonymization: Microsoft Presidiopresidio-analyzerpresidio-anonymizerNLP Model: spacy (반드시 en_core_web_lg 모델 사용)AI Engine: Google Gemini 3.0 APISDK: google-genai (최신 SDK 사용, 구버전 google.generativeai 사용 금지)Model ID: gemini-3.0-pro-preview (또는 현재 사용 가능한 최신 3.0 버전)Environment: pip 및 venv 사용3. 핵심 기능 및 아키텍처 요구사항3.1 보안 계층 (The Security Layer)원칙: "Zero Trust". 사용자가 업로드한 원본 데이터(Raw Data)는 절대로 AI 엔진으로 직접 전송되어서는 안 됩니다.구현 지시:SecurityEngine 클래스를 별도 파일(security_utils.py)로 분리하십시오.Presidio의 AnalyzerEngine과 AnonymizerEngine은 클래스 초기화 시 한 번만 로드하여(Singleton 패턴 권장) 성능을 최적화하십시오.Pandas DataFrame을 입력받아 **문자열 컬럼(Object type)**에 대해서만 PII 검사를 수행하는 anonymize_dataframe 메서드를 구현하십시오.익명화 오퍼레이터는 'Replace'를 사용하여 <PERSON>, <EMAIL>, <PHONE> 형식으로 치환하십시오. 이는 AI가 문맥을 파악하기 위함입니다.spacy의 en_core_web_lg 모델 다운로드 스크립트를 setup.sh 또는 README.md에 명시하십시오.3.2 AI 인텔리전스 계층 (The Intelligence Layer)구현 지시:AIEngine 클래스를 별도 파일(ai_utils.py)로 구현하십시오.google-genai 라이브러리의 Client 객체를 사용하십시오.설정 필수 사항: Gemini 3.0의 환각 방지와 분석 정확도를 위해 temperature 파라미터를 반드시 0.1로 설정하십시오 (기본값 1.0 사용 금지).시스템 프롬프트(System Instruction)에 다음을 포함하십시오:"당신은 데이터 분석 전문가입니다. 입력된 데이터는 개인정보 보호를 위해 익명화 처리되었습니다(예: ). 익명화된 태그를 실제 값으로 복원하려 하지 말고, 데이터의 패턴과 통계적 의미를 분석하는 데 집중하십시오."대용량 데이터 처리를 위해, 데이터프레임이 너무 클 경우 상위 N행(예: 50행)과 df.describe() 요약 정보만을 전송하는 로직을 포함하십시오.3.3 사용자 인터페이스 (Streamlit UI)구현 지시:app.py를 메인 엔트리 포인트로 작성하십시오.사이드바: API 키 입력(Password 타입), 파일 업로더(CSV), PII 처리 옵션(원본 보기/익명화 결과 보기 토글)을 배치하십시오.메인 화면:업로드된 데이터의 미리보기 (Pandas DataFrame)."AI 분석 실행" 버튼.버튼 클릭 시 st.spinner("PII 식별 및 익명화 수행 중...") -> Presidio 처리 -> st.spinner("Gemini 3.0이 데이터를 분석 중입니다...") -> AI 호출 순서로 진행하십시오.AI 응답은 마크다운 형식으로 깔끔하게 렌더링하십시오.에러 처리: API 키 누락, 파일 형식 오류, 429 Rate Limit 에러 등에 대한 st.error 처리를 구현하십시오.4. 작업 절차 (Workflow Instruction)Planning Mode 진입: 먼저 프로젝트 디렉토리 구조와 각 파일(app.py, security_utils.py, ai_utils.py, requirements.txt)의 역할이 정의된 상세 계획(PLAN.md)을 작성하여 저에게 제시하십시오.의존성 확인: requirements.txt에 필요한 모든 패키지 버전이 명시되어 있는지 확인하십시오.코드 생성: 계획이 승인되면 코드를 생성하되, 각 모듈이 독립적으로 작동하는지 검증할 수 있는 테스트 코드(test_security.py)도 함께 제안하십시오.지금 바로 **[Phase 1 Implementation Plan]**을 작성해 주세요.5. 실행 전략 및 단계별 상세 분석5.1 1단계: 환경 설정 및 의존성 주입 (Environment Setup)Antigravity 에이전트는 가장 먼저 환경을 구축하려 할 것이다. 이때 가장 중요한 것은 NLP 모델의 설치다. Presidio가 의존하는 Spacy 모델(en_core_web_lg)은 일반적인 pip install로는 설치되지 않으며, 별도의 다운로드 명령어(python -m spacy download...)가 필요하다. 마스터 프롬프트에서 이를 명시한 이유는, 에이전트가 이를 누락하여 런타임 에러(Runtime Error)가 발생하는 "바이브 코딩의 흔한 실패 사례"를 방지하기 위함이다.또한, google-genai 라이브러리 버전 충돌을 막기 위해 가상 환경(venv) 내에서 깨끗한 설치를 유도해야 한다. requirements.txt에는 버전 핀(Version Pinning)을 사용하는 것이 좋으나, Gemini 3.0 관련 SDK는 빠르게 업데이트되므로 최신 버전을 유지하는 전략이 유효하다.5.2 2단계: 보안 모듈 구현 (Security Engine Implementation)Presidio의 통합은 이 프로젝트의 가장 큰 병목 구간(Bottleneck)이 될 가능성이 높다. 텍스트 분석은 CPU 집약적인 작업이기 때문이다.최적화 전략: 데이터프레임 전체를 순회하는 것은 비효율적이다. 따라서 df.select_dtypes(include=['object'])를 사용하여 문자열 컬럼만 필터링한 후 Presidio에 전달하도록 에이전트를 유도해야 한다.검증: 에이전트에게 test_security.py 작성을 지시한 것은, UI 없이도 보안 모듈이 정상적으로 PII(이름, 전화번호 등)를 감지하는지 "단위 테스트"를 하기 위함이다. 이는 전체 앱을 실행하지 않고도 핵심 기능을 검증할 수 있게 해 준다.5.3 3단계: Gemini 3.0 연동 (AI Integration)google-genai SDK를 사용한 3.0 API 호출부는 비동기 처리가 권장된다. 하지만 Streamlit은 기본적으로 동기식(Synchronous) 구조를 가진다.상태 관리: AI 분석 결과가 화면 리프레시(Refresh) 시 사라지지 않도록 st.session_state에 결과를 저장하는 로직이 필수적이다. 마스터 프롬프트에서 이를 암시적으로 요구하고 있지만, 에이전트가 코드를 생성할 때 이 부분(Session State 활용)을 누락한다면 "코드 리뷰" 단계에서 지적해야 한다.프롬프트 엔지니어링 내재화: 시스템 프롬프트에 "익명화된 데이터를 분석한다"는 컨텍스트를 주입하는 것은 매우 중요하다. 그렇지 않으면 Gemini 3.0은 <PERSON>이라는 텍스트를 보고 "데이터가 깨졌다"거나 "누락되었다"고 판단할 수 있기 때문이다.5.4 4단계: UI 구성 및 사용자 경험 (Frontend UX)Streamlit의 st.data_editor를 활용하면 사용자가 AI에게 보내기 전에 데이터가 어떻게 변했는지(익명화 결과)를 눈으로 확인할 수 있다. 이는 "Human-in-the-loop" 보안 검증 절차를 UI에 자연스럽게 녹여내는 방법이다. 사용자는 AI가 분석하기 전, Presidio가 놓친 PII가 있는지 육안으로 검사할 수 있는 기회를 갖게 된다.6. 잠재적 위험 요소 및 대응 방안 (Risk Management)6.1 컨텍스트 윈도우 초과 및 비용 문제Gemini 3.0이 100만 토큰을 지원한다고 해서 무제한으로 데이터를 던지는 것은 위험하다. 토큰당 과금 모델일 경우 비용이 급증할 수 있고, 처리 속도가 느려질 수 있다.대응: 마스터 프롬프트에 포함된 "데이터 샘플링(Sampling) 로직"이 1차 방어선이다. 향후 Phase 2에서는 RAG(검색 증강 생성) 기술을 도입하여 전체 데이터를 벡터 DB에 넣고 필요한 부분만 검색해오는 방식으로 고도화해야 한다.6.2 Presidio의 오탐(False Positive) 및 미탐(False Negative)Presidio가 모든 한국어 이름이나 특수한 ID 형식을 100% 잡아낸다는 보장은 없다. 특히 영어 모델(en_core_web_lg)을 사용할 경우 한국어 PII 처리에 한계가 있을 수 있다.대응: 프로토타입 단계에서는 영문 데이터셋을 기준으로 검증하되, 향후 한국어 특화 모델(KoBERT 등)을 커스텀 Recognizer로 추가하는 확장이 필요함을 인지해야 한다. 마스터 프롬프트는 '확장 가능한 클래스 구조'를 요구함으로써 이에 대비한다.6.3 Gemini 3.0의 '과도한 창의성'온도(Temperature) 설정을 0.1로 낮추더라도, 생성형 모델은 본질적으로 확률적이다.대응: AI가 생성한 분석 결과 하단에 "이 분석은 AI에 의해 생성되었으며, 실제 데이터와 차이가 있을 수 있습니다"라는 면책 조항(Disclaimer)을 UI에 명시하도록 코드를 유도해야 한다.7. 결론본 보고서는 단순한 코드 작성이 아니라, **'보안이 담보된 고지능 AI 애플리케이션'**을 구글 Antigravity라는 최신 도구를 통해 구축하는 포괄적인 가이드라인이다. 제안된 마스터 프롬프트는 Gemini 3.0의 강력한 성능을 활용하면서도, Presidio를 통해 엔터프라이즈급 보안 요구사항을 충족시키는 균형점을 제시하고 있다.Phase 1 프로토타입의 성공은 에이전트가 이 프롬프트를 얼마나 정확히 이해하고 계획(Plan)을 수립하느냐에 달려 있다. 따라서 개발자는 Antigravity의 'Planning Mode'에서 생성되는 PLAN.md를 면밀히 검토하고, 보안 모듈이 AI 모듈보다 선행하여 작동하는지 아키텍처 흐름을 승인하는 '디렉터'로서의 역할에 충실해야 할 것이다. 이것이 바로 바이브 코딩 시대가 요구하는 새로운 개발자의 역량이다.